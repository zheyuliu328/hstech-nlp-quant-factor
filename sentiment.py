#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
sentiment.py
---------------------------------
æƒ…æ„Ÿåˆ†ææ¨¡å—ï¼šä¸ºæ¸…æ´—åçš„æ–°é—»æ•°æ®æ·»åŠ æƒ…æ„Ÿåˆ†æ•°

åŠŸèƒ½åŒ…æ‹¬ï¼š
- è¯»å–æ¸…æ´—åçš„æ–°é—»æ•°æ®
- ä½¿ç”¨ cardiffnlp/twitter-roberta-base-sentiment-latest æ¨¡å‹è¿›è¡Œæƒ…æ„Ÿåˆ†æ
- å°†æƒ…æ„Ÿæ ‡ç­¾è½¬æ¢ä¸ºæ•°å€¼åˆ†æ•°
- ä¿å­˜å¸¦æœ‰ sentiment_score åˆ—çš„ç»“æœ

Author: ChatGPT (Market Alpha: NLP-Driven Factor Study)
"""

import pandas as pd
import logging
import argparse
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
import time
try:
    import torch
    from transformers import pipeline
except ImportError as e:
    print(f"è­¦å‘Š: æ— æ³•å¯¼å…¥ torch æˆ– transformers: {e}")
    print("è¯·å®‰è£…: pip install torch transformers")
    torch = None
    pipeline = None

# --- é…ç½® ---
DEFAULT_INPUT_FILE = 'data/processed/articles_recent_cleaned.csv'
DEFAULT_OUTPUT_FILE = 'data/processed/articles_with_sentiment.csv'
DEFAULT_TEXT_COLUMN = 'body'  # æ¸…æ´—åæ•°æ®ä¸­çš„æ–‡æœ¬åˆ—å
DEFAULT_BATCH_SIZE = 32  # æ ¹æ®å†…å­˜æƒ…å†µè°ƒæ•´
MODEL_NAME = 'cardiffnlp/twitter-roberta-base-sentiment-latest'
# --- ç»“æŸé…ç½® ---

def convert_sentiment_to_score(sentiment_label: str, confidence: float) -> float:
    """
    å°†æƒ…æ„Ÿæ ‡ç­¾è½¬æ¢ä¸ºæ•°å€¼åˆ†æ•°
    
    Args:
        sentiment_label: æƒ…æ„Ÿæ ‡ç­¾ ('LABEL_0', 'LABEL_1', 'LABEL_2' æˆ– 'NEGATIVE', 'NEUTRAL', 'POSITIVE')
        confidence: ç½®ä¿¡åº¦åˆ†æ•°
        
    Returns:
        æƒ…æ„Ÿåˆ†æ•° (-1.0 åˆ° 1.0ï¼Œè´Ÿæ•°è¡¨ç¤ºè´Ÿé¢ï¼Œæ­£æ•°è¡¨ç¤ºæ­£é¢ï¼Œ0è¡¨ç¤ºä¸­æ€§)
    """
    # å¤„ç†ä¸åŒçš„æ ‡ç­¾æ ¼å¼
    if sentiment_label in ['LABEL_0', 'NEGATIVE', 'negative']:
        return -confidence  # è´Ÿé¢æƒ…æ„Ÿï¼Œç½®ä¿¡åº¦è¶Šé«˜åˆ†æ•°è¶Šè´Ÿ
    elif sentiment_label in ['LABEL_1', 'NEUTRAL', 'neutral']:
        return 0.0  # ä¸­æ€§æƒ…æ„Ÿï¼Œåˆ†æ•°ä¸º0
    elif sentiment_label in ['LABEL_2', 'POSITIVE', 'positive']:
        return confidence  # æ­£é¢æƒ…æ„Ÿï¼Œç½®ä¿¡åº¦è¶Šé«˜åˆ†æ•°è¶Šæ­£
    else:
        logging.warning(f"æœªçŸ¥çš„æƒ…æ„Ÿæ ‡ç­¾: {sentiment_label}")
        return 0.0


def load_cleaned_data(input_file: str, text_column: str) -> pd.DataFrame:
    """
    åŠ è½½æ¸…æ´—åçš„æ•°æ®
    
    Args:
        input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
        text_column: æ–‡æœ¬åˆ—å
        
    Returns:
        åŠ è½½çš„æ•°æ®æ¡†
    """
    logging.info(f"å¼€å§‹åŠ è½½æ•°æ®: {input_file}")
    
    if not Path(input_file).exists():
        raise FileNotFoundError(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
    
    try:
        # å°è¯•ä¸åŒçš„ç¼–ç æ–¹å¼
        for encoding in ['utf-8', 'utf-8-sig', 'latin-1', 'cp1252']:
            try:
                df = pd.read_csv(input_file, encoding=encoding)
                logging.info(f"æˆåŠŸä½¿ç”¨ {encoding} ç¼–ç åŠ è½½æ•°æ®")
                break
            except UnicodeDecodeError:
                continue
        else:
            raise ValueError("æ— æ³•ä½¿ç”¨ä»»ä½•ç¼–ç æ–¹å¼è¯»å–æ–‡ä»¶")
            
    except Exception as e:
        raise ValueError(f"åŠ è½½æ–‡ä»¶æ—¶å‡ºé”™: {e}")
    
    # æ£€æŸ¥æ–‡æœ¬åˆ—æ˜¯å¦å­˜åœ¨
    if text_column not in df.columns:
        available_cols = df.columns.tolist()
        raise ValueError(f"æ–‡æœ¬åˆ— '{text_column}' åœ¨æ–‡ä»¶ä¸­æœªæ‰¾åˆ°ã€‚å¯ç”¨åˆ—: {available_cols}")
    
    # æ¸…ç†æ•°æ®ï¼šåˆ é™¤æ–‡æœ¬åˆ—ä¸ºç©ºæˆ–åªæœ‰ç©ºæ ¼çš„è¡Œ
    original_rows = len(df)
    df = df.dropna(subset=[text_column])
    df = df[df[text_column].astype(str).str.strip() != '']
    rows_after_cleaning = len(df)
    
    if rows_after_cleaning < original_rows:
        logging.info(f"æ¸…ç†æ•°æ®ï¼šåˆ é™¤äº† {original_rows - rows_after_cleaning} è¡Œç©ºæ–‡æœ¬")
    
    logging.info(f"æ‰¾åˆ° {rows_after_cleaning} æ¡æœ‰æ•ˆæ–°é—»è¿›è¡Œæƒ…æ„Ÿåˆ†æ")
    
    return df

def load_sentiment_model() -> pipeline:
    """
    åŠ è½½æƒ…æ„Ÿåˆ†ææ¨¡å‹
    
    Returns:
        åŠ è½½çš„pipelineå¯¹è±¡
    """
    logging.info("æ­£åœ¨åŠ è½½ Transformer æƒ…æ„Ÿåˆ†ææ¨¡å‹ (å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿ)...")
    start_load_time = time.time()
    
    # æ£€æŸ¥æ˜¯å¦æœ‰å¯ç”¨çš„GPU
    if torch is None:
        raise RuntimeError("torch æœªå®‰è£…ï¼Œè¯·è¿è¡Œ: pip install torch")
    
    device_num = 0 if torch.cuda.is_available() else -1
    device_name = "GPU" if device_num == 0 else "CPU"
    logging.info(f"å°†ä½¿ç”¨è®¾å¤‡: {device_name}")
    
    try:
        sentiment_pipeline = pipeline(
            "sentiment-analysis",
            model=MODEL_NAME,
            tokenizer=MODEL_NAME,
            device=device_num
        )
        
        load_time = time.time() - start_load_time
        logging.info(f"æ¨¡å‹åŠ è½½å®Œæˆï¼Œè€—æ—¶: {load_time:.2f} ç§’")
        
        return sentiment_pipeline
        
    except Exception as e:
        logging.error(f"åŠ è½½æ¨¡å‹æ—¶å‡ºé”™: {e}")
        raise RuntimeError("è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’Œåº“å®‰è£…æƒ…å†µ")


def analyze_sentiment_batch(
    texts: List[str], 
    sentiment_pipeline: pipeline, 
    batch_size: int = DEFAULT_BATCH_SIZE
) -> List[Dict[str, Any]]:
    """
    æ‰¹é‡è¿›è¡Œæƒ…æ„Ÿåˆ†æ
    
    Args:
        texts: æ–‡æœ¬åˆ—è¡¨
        sentiment_pipeline: æƒ…æ„Ÿåˆ†æpipeline
        batch_size: æ‰¹å¤„ç†å¤§å°
        
    Returns:
        æƒ…æ„Ÿåˆ†æç»“æœåˆ—è¡¨
    """
    logging.info(f"å¼€å§‹æƒ…æ„Ÿåˆ†æ (åˆ†æ‰¹å¤„ç†ï¼Œæ¯æ‰¹ {batch_size} æ¡)...")
    logging.info("è¿™å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œå°¤å…¶æ˜¯åœ¨CPUä¸Šã€‚è¯·è€å¿ƒç­‰å¾…...")
    
    all_results = []
    analysis_start_time = time.time()
    
    # åˆ†æ‰¹å¤„ç†
    for i in range(0, len(texts), batch_size):
        batch = texts[i : i + batch_size]
        try:
            # ä½¿ç”¨pipelineè¿›è¡Œæƒ…æ„Ÿåˆ†æ
            results = sentiment_pipeline(batch, truncation=True, max_length=512)
            all_results.extend(results)
            
        except Exception as e:
            logging.error(f"å¤„ç†æ‰¹æ¬¡ {i//batch_size + 1} æ—¶å‡ºé”™: {e}")
            # å¦‚æœä¸€æ‰¹å‡ºé”™ï¼Œç”¨é»˜è®¤å€¼å¡«å……
            error_results = [{'label': 'LABEL_1', 'score': 0.5} for _ in batch]
            all_results.extend(error_results)
        
        # æ‰“å°è¿›åº¦
        if (i // batch_size + 1) % 10 == 0 or i + len(batch) >= len(texts):
            elapsed_time = time.time() - analysis_start_time
            processed = min(i + len(batch), len(texts))
            estimated_total_time = (elapsed_time / processed) * len(texts) if processed > 0 else 0
            logging.info(f"å·²å¤„ç† {processed} / {len(texts)} æ¡æ–°é—»ã€‚"
                        f"è€—æ—¶: {elapsed_time:.1f}s (é¢„è®¡æ€»è€—æ—¶: {estimated_total_time:.1f}s)")
    
    analysis_time = time.time() - analysis_start_time
    logging.info(f"æƒ…æ„Ÿåˆ†æå®Œæˆï¼Œæ€»è€—æ—¶: {analysis_time:.2f} ç§’")
    
    return all_results

def add_sentiment_scores(
    df: pd.DataFrame, 
    sentiment_results: List[Dict[str, Any]], 
    text_column: str
) -> pd.DataFrame:
    """
    å°†æƒ…æ„Ÿåˆ†æç»“æœæ·»åŠ åˆ°æ•°æ®æ¡†
    
    Args:
        df: åŸå§‹æ•°æ®æ¡†
        sentiment_results: æƒ…æ„Ÿåˆ†æç»“æœ
        text_column: æ–‡æœ¬åˆ—å
        
    Returns:
        æ·»åŠ äº†æƒ…æ„Ÿåˆ†æ•°åˆ—çš„æ•°æ®æ¡†
    """
    if len(sentiment_results) != len(df):
        raise ValueError(f"æƒ…æ„Ÿåˆ†æç»“æœæ•°é‡ ({len(sentiment_results)}) ä¸æ•°æ®è¡Œæ•° ({len(df)}) ä¸åŒ¹é…")
    
    # åˆ›å»ºç»“æœæ•°æ®æ¡†
    df_result = df.copy()
    
    # æå–æƒ…æ„Ÿæ ‡ç­¾å’Œç½®ä¿¡åº¦
    sentiment_labels = [result['label'] for result in sentiment_results]
    sentiment_scores = [result['score'] for result in sentiment_results]
    
    # è½¬æ¢ä¸ºæ•°å€¼åˆ†æ•°
    numeric_scores = [
        convert_sentiment_to_score(label, score) 
        for label, score in zip(sentiment_labels, sentiment_scores)
    ]
    
    # æ·»åŠ æ–°åˆ—
    df_result['sentiment_label'] = sentiment_labels
    df_result['sentiment_confidence'] = sentiment_scores
    df_result['sentiment_score'] = numeric_scores
    
    # ç»Ÿè®¡æƒ…æ„Ÿåˆ†å¸ƒ
    sentiment_distribution = pd.Series(sentiment_labels).value_counts()
    logging.info(f"æƒ…æ„Ÿæ ‡ç­¾åˆ†å¸ƒ:\n{sentiment_distribution}")
    
    # ç»Ÿè®¡åˆ†æ•°åˆ†å¸ƒ
    score_stats = pd.Series(numeric_scores).describe()
    logging.info(f"æƒ…æ„Ÿåˆ†æ•°ç»Ÿè®¡:\n{score_stats}")
    
    return df_result


def save_results(df: pd.DataFrame, output_file: str) -> None:
    """
    ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
    
    Args:
        df: ç»“æœæ•°æ®æ¡†
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    output_path = Path(output_file)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    logging.info(f"æ­£åœ¨å°†ç»“æœä¿å­˜åˆ°: {output_file}")
    
    try:
        # ä½¿ç”¨ utf-8-sig ç¼–ç ä»¥ä¾¿ Excel èƒ½æ›´å¥½åœ°è¯†åˆ« UTF-8
        df.to_csv(output_file, index=False, encoding='utf-8-sig')
        logging.info("æ–‡ä»¶ä¿å­˜æˆåŠŸ")
        
    except Exception as e:
        logging.error(f"ä¿å­˜æ–‡ä»¶æ—¶å‡ºé”™: {e}")
        raise


def process_sentiment_analysis(
    input_file: str,
    output_file: str,
    text_column: str = DEFAULT_TEXT_COLUMN,
    batch_size: int = DEFAULT_BATCH_SIZE
) -> pd.DataFrame:
    """
    æ‰§è¡Œå®Œæ•´çš„æƒ…æ„Ÿåˆ†ææµç¨‹
    
    Args:
        input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        text_column: æ–‡æœ¬åˆ—å
        batch_size: æ‰¹å¤„ç†å¤§å°
        
    Returns:
        å¤„ç†åçš„æ•°æ®æ¡†
    """
    # 1. åŠ è½½æ•°æ®
    df = load_cleaned_data(input_file, text_column)
    
    # 2. åŠ è½½æ¨¡å‹
    sentiment_pipeline = load_sentiment_model()
    
    # 3. è·å–æ–‡æœ¬åˆ—è¡¨
    texts = df[text_column].astype(str).tolist()
    
    # 4. è¿›è¡Œæƒ…æ„Ÿåˆ†æ
    sentiment_results = analyze_sentiment_batch(texts, sentiment_pipeline, batch_size)
    
    # 5. æ·»åŠ æƒ…æ„Ÿåˆ†æ•°
    df_with_sentiment = add_sentiment_scores(df, sentiment_results, text_column)
    
    # 6. ä¿å­˜ç»“æœ
    save_results(df_with_sentiment, output_file)
    
    return df_with_sentiment


def main():
    """
    å‘½ä»¤è¡Œå…¥å£å‡½æ•°
    """
    parser = argparse.ArgumentParser(description="ä¸ºæ–°é—»æ•°æ®æ·»åŠ æƒ…æ„Ÿåˆ†æ•°")
    parser.add_argument("--input", "-i", default=DEFAULT_INPUT_FILE, help="è¾“å…¥æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--output", "-o", default=DEFAULT_OUTPUT_FILE, help="è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--text_column", "-t", default=DEFAULT_TEXT_COLUMN, help="æ–‡æœ¬åˆ—å")
    parser.add_argument("--batch_size", "-b", type=int, default=DEFAULT_BATCH_SIZE, help="æ‰¹å¤„ç†å¤§å°")
    parser.add_argument("--verbose", "-v", action="store_true", help="è¯¦ç»†æ—¥å¿—")
    
    args = parser.parse_args()
    
    # é…ç½®æ—¥å¿—
    log_level = logging.DEBUG if args.verbose else logging.INFO
    logging.basicConfig(
        level=log_level,
        format='%(asctime)s %(levelname)s %(message)s',
        handlers=[logging.StreamHandler()]
    )
    
    try:
        # æ‰§è¡Œæƒ…æ„Ÿåˆ†æ
        df_result = process_sentiment_analysis(
            input_file=args.input,
            output_file=args.output,
            text_column=args.text_column,
            batch_size=args.batch_size
        )
        
        print(f"\nâœ… æƒ…æ„Ÿåˆ†æå®Œæˆ!")
        print(f"ğŸ“Š å¤„ç†è®°å½•æ•°: {len(df_result)}")
        print(f"ğŸ“ˆ æƒ…æ„Ÿåˆ†æ•°èŒƒå›´: {df_result['sentiment_score'].min():.3f} åˆ° {df_result['sentiment_score'].max():.3f}")
        print(f"ğŸ“ ç»“æœå·²ä¿å­˜åˆ°: {args.output}")
        
    except Exception as e:
        logging.error(f"æƒ…æ„Ÿåˆ†æå¤±è´¥: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())