#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
generate_factors.py
---------------------------------
ç”Ÿæˆæƒ…æ„Ÿå› å­å¹¶è¿›è¡Œè¯„ä¼°çš„ä¸»è„šæœ¬

åŠŸèƒ½åŒ…æ‹¬ï¼š
- ä»æƒ…æ„Ÿåˆ†ææ•°æ®ç”Ÿæˆæ—¥åº¦å› å­
- è®¡ç®—å› å­ä¸æœªæ¥æ”¶ç›Šçš„IC
- è¾“å‡ºå› å­æ•°æ®å’Œè¯„ä¼°ç»“æœ

Author: ChatGPT (Market Alpha: NLP-Driven Factor Study)
"""

import pandas as pd
import numpy as np
import logging
import argparse
from pathlib import Path
from typing import Dict, Any

# å¯¼å…¥æˆ‘ä»¬çš„æ¨¡å—
from factors import daily_factor_from_sentiment
from eval import add_fwd_return, ic_by_day, comprehensive_evaluation, monthly_summary

# --- é…ç½® ---
DEFAULT_SENTIMENT_FILE = 'data/processed/articles_with_sentiment.csv'
DEFAULT_PRICES_FILE = 'data/prices.csv'
DEFAULT_FACTOR_OUTPUT = 'data/processed/daily_sentiment_factors.csv'
DEFAULT_IC_OUTPUT = 'data/processed/ic_results.csv'
DEFAULT_EVAL_OUTPUT = 'data/processed/factor_evaluation.json'
# --- ç»“æŸé…ç½® ---

def load_sentiment_data(sentiment_file: str) -> pd.DataFrame:
    """
    åŠ è½½æƒ…æ„Ÿåˆ†ææ•°æ®
    
    Args:
        sentiment_file: æƒ…æ„Ÿåˆ†ææ•°æ®æ–‡ä»¶è·¯å¾„
        
    Returns:
        åŠ è½½çš„æ•°æ®æ¡†
    """
    logging.info(f"åŠ è½½æƒ…æ„Ÿåˆ†ææ•°æ®: {sentiment_file}")
    
    if not Path(sentiment_file).exists():
        raise FileNotFoundError(f"æƒ…æ„Ÿåˆ†ææ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {sentiment_file}")
    
    try:
        df = pd.read_csv(sentiment_file, encoding='utf-8-sig')
        logging.info(f"æˆåŠŸåŠ è½½ {len(df)} æ¡æƒ…æ„Ÿåˆ†æè®°å½•")
        
        # ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®
        df['date'] = pd.to_datetime(df['date']).dt.date
        
        # æ£€æŸ¥å¿…è¦çš„åˆ—
        required_cols = ['date', 'code', 'sentiment_score']
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            raise ValueError(f"ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_cols}")
        
        return df
        
    except Exception as e:
        raise ValueError(f"åŠ è½½æƒ…æ„Ÿåˆ†ææ•°æ®æ—¶å‡ºé”™: {e}")


def load_price_data(prices_file: str) -> pd.DataFrame:
    """
    åŠ è½½ä»·æ ¼æ•°æ®
    
    Args:
        prices_file: ä»·æ ¼æ•°æ®æ–‡ä»¶è·¯å¾„
        
    Returns:
        åŠ è½½çš„æ•°æ®æ¡†
    """
    logging.info(f"åŠ è½½ä»·æ ¼æ•°æ®: {prices_file}")
    
    if not Path(prices_file).exists():
        raise FileNotFoundError(f"ä»·æ ¼æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {prices_file}")
    
    try:
        df = pd.read_csv(prices_file, encoding='utf-8-sig')
        logging.info(f"æˆåŠŸåŠ è½½ {len(df)} æ¡ä»·æ ¼è®°å½•")
        
        # ç¡®ä¿æ—¥æœŸæ ¼å¼æ­£ç¡®
        df['date'] = pd.to_datetime(df['date']).dt.date
        
        # æ£€æŸ¥å¿…è¦çš„åˆ—
        required_cols = ['date', 'code', 'close']
        missing_cols = [col for col in required_cols if col not in df.columns]
        if missing_cols:
            raise ValueError(f"ç¼ºå°‘å¿…è¦çš„åˆ—: {missing_cols}")
        
        return df
        
    except Exception as e:
        raise ValueError(f"åŠ è½½ä»·æ ¼æ•°æ®æ—¶å‡ºé”™: {e}")


def generate_factors(sentiment_df: pd.DataFrame) -> pd.DataFrame:
    """
    ç”Ÿæˆæ—¥åº¦å› å­
    
    Args:
        sentiment_df: æƒ…æ„Ÿåˆ†ææ•°æ®æ¡†
        
    Returns:
        æ—¥åº¦å› å­æ•°æ®æ¡†
    """
    logging.info("å¼€å§‹ç”Ÿæˆæ—¥åº¦å› å­...")
    
    # ä½¿ç”¨æˆ‘ä»¬çš„å› å­ç”Ÿæˆå‡½æ•°
    factors_df = daily_factor_from_sentiment(sentiment_df)
    
    logging.info(f"ç”Ÿæˆäº† {len(factors_df)} ä¸ªæ—¥åº¦å› å­è®°å½•")
    logging.info(f"è¦†ç›– {factors_df['date'].nunique()} ä¸ªäº¤æ˜“æ—¥")
    logging.info(f"è¦†ç›– {factors_df['code'].nunique()} åªè‚¡ç¥¨")
    
    return factors_df


def calculate_ic(factors_df: pd.DataFrame, prices_df: pd.DataFrame) -> pd.DataFrame:
    """
    è®¡ç®—IC
    
    Args:
        factors_df: å› å­æ•°æ®æ¡†
        prices_df: ä»·æ ¼æ•°æ®æ¡†
        
    Returns:
        ICç»“æœæ•°æ®æ¡†
    """
    logging.info("å¼€å§‹è®¡ç®—IC...")
    
    # æ·»åŠ å‰ç»æ”¶ç›Šç‡
    prices_with_returns = add_fwd_return(prices_df)
    
    # è®¡ç®—IC
    ic_results = ic_by_day(factors_df, prices_with_returns, 'sentiment_factor')
    
    logging.info(f"è®¡ç®—äº† {len(ic_results)} ä¸ªäº¤æ˜“æ—¥çš„IC")
    
    return ic_results


def evaluate_factors(ic_df: pd.DataFrame) -> Dict[str, Any]:
    """
    è¯„ä¼°å› å­è¡¨ç°
    
    Args:
        ic_df: ICæ•°æ®æ¡†
        
    Returns:
        è¯„ä¼°ç»“æœå­—å…¸
    """
    logging.info("å¼€å§‹è¯„ä¼°å› å­è¡¨ç°...")
    
    # ç»¼åˆè¯„ä¼°
    eval_results = comprehensive_evaluation(ic_df)
    
    # æœˆåº¦æ‘˜è¦
    monthly_stats = monthly_summary(ic_df)
    
    return {
        'comprehensive': eval_results,
        'monthly_stats': monthly_stats.to_dict('records') if not monthly_stats.empty else []
    }


def save_results(factors_df: pd.DataFrame, ic_df: pd.DataFrame, 
                eval_results: Dict[str, Any], 
                factor_output: str, ic_output: str, eval_output: str) -> None:
    """
    ä¿å­˜ç»“æœ
    
    Args:
        factors_df: å› å­æ•°æ®æ¡†
        ic_df: ICæ•°æ®æ¡†
        eval_results: è¯„ä¼°ç»“æœ
        factor_output: å› å­è¾“å‡ºæ–‡ä»¶è·¯å¾„
        ic_output: ICè¾“å‡ºæ–‡ä»¶è·¯å¾„
        eval_output: è¯„ä¼°è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    for output_file in [factor_output, ic_output, eval_output]:
        Path(output_file).parent.mkdir(parents=True, exist_ok=True)
    
    # ä¿å­˜å› å­æ•°æ®
    logging.info(f"ä¿å­˜å› å­æ•°æ®åˆ°: {factor_output}")
    factors_df.to_csv(factor_output, index=False, encoding='utf-8-sig')
    
    # ä¿å­˜ICæ•°æ®
    logging.info(f"ä¿å­˜ICæ•°æ®åˆ°: {ic_output}")
    ic_df.to_csv(ic_output, index=False, encoding='utf-8-sig')
    
    # ä¿å­˜è¯„ä¼°ç»“æœ
    logging.info(f"ä¿å­˜è¯„ä¼°ç»“æœåˆ°: {eval_output}")
    import json
    with open(eval_output, 'w', encoding='utf-8') as f:
        json.dump(eval_results, f, ensure_ascii=False, indent=2)


def print_evaluation_summary(eval_results: Dict[str, Any]) -> None:
    """
    æ‰“å°è¯„ä¼°æ‘˜è¦
    
    Args:
        eval_results: è¯„ä¼°ç»“æœå­—å…¸
    """
    comp = eval_results['comprehensive']
    
    print("\n" + "="*60)
    print("ğŸ¯ æƒ…æ„Ÿå› å­è¯„ä¼°ç»“æœ")
    print("="*60)
    
    print(f"ğŸ“Š æ•°æ®æ¦‚è§ˆ:")
    print(f"   â€¢ æ€»äº¤æ˜“æ—¥æ•°: {comp['total_days']}")
    
    print(f"\nğŸ“ˆ ICç»Ÿè®¡:")
    print(f"   â€¢ ICå‡å€¼: {comp['ic_mean']:.4f}")
    print(f"   â€¢ ICæ ‡å‡†å·®: {comp['ic_std']:.4f}")
    print(f"   â€¢ IC tç»Ÿè®¡é‡: {comp['ic_t_stat']:.4f}")
    print(f"   â€¢ ICä¿¡æ¯æ¯”ç‡: {comp['ic_ir']:.4f}")
    print(f"   â€¢ æ­£ICæ¯”ä¾‹: {comp['positive_ic_ratio']:.2%}")
    
    print(f"\nğŸ“Š Rank-ICç»Ÿè®¡:")
    print(f"   â€¢ Rank-ICå‡å€¼: {comp['rank_ic_mean']:.4f}")
    print(f"   â€¢ Rank-ICæ ‡å‡†å·®: {comp['rank_ic_std']:.4f}")
    print(f"   â€¢ Rank-IC tç»Ÿè®¡é‡: {comp['rank_ic_t_stat']:.4f}")
    print(f"   â€¢ Rank-ICä¿¡æ¯æ¯”ç‡: {comp['rank_ic_ir']:.4f}")
    print(f"   â€¢ æ­£Rank-ICæ¯”ä¾‹: {comp['positive_rank_ic_ratio']:.2%}")
    
    # åˆ¤æ–­å› å­æœ‰æ•ˆæ€§
    if abs(comp['ic_t_stat']) > 2.0:
        print(f"\nâœ… å› å­æœ‰æ•ˆæ€§: å¼º (|tç»Ÿè®¡é‡| = {abs(comp['ic_t_stat']):.2f} > 2.0)")
    elif abs(comp['ic_t_stat']) > 1.5:
        print(f"\nâš ï¸  å› å­æœ‰æ•ˆæ€§: ä¸­ç­‰ (|tç»Ÿè®¡é‡| = {abs(comp['ic_t_stat']):.2f} > 1.5)")
    else:
        print(f"\nâŒ å› å­æœ‰æ•ˆæ€§: å¼± (|tç»Ÿè®¡é‡| = {abs(comp['ic_t_stat']):.2f} < 1.5)")
    
    print("="*60)


def main():
    """
    ä¸»å‡½æ•°
    """
    parser = argparse.ArgumentParser(description="ç”Ÿæˆæƒ…æ„Ÿå› å­å¹¶è¿›è¡Œè¯„ä¼°")
    parser.add_argument("--sentiment_file", "-s", default=DEFAULT_SENTIMENT_FILE, 
                       help="æƒ…æ„Ÿåˆ†ææ•°æ®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--prices_file", "-p", default=DEFAULT_PRICES_FILE, 
                       help="ä»·æ ¼æ•°æ®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--factor_output", "-fo", default=DEFAULT_FACTOR_OUTPUT, 
                       help="å› å­è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--ic_output", "-io", default=DEFAULT_IC_OUTPUT, 
                       help="ICè¾“å‡ºæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--eval_output", "-eo", default=DEFAULT_EVAL_OUTPUT, 
                       help="è¯„ä¼°è¾“å‡ºæ–‡ä»¶è·¯å¾„")
    parser.add_argument("--verbose", "-v", action="store_true", help="è¯¦ç»†æ—¥å¿—")
    
    args = parser.parse_args()
    
    # é…ç½®æ—¥å¿—
    log_level = logging.DEBUG if args.verbose else logging.INFO
    logging.basicConfig(
        level=log_level,
        format='%(asctime)s %(levelname)s %(message)s',
        handlers=[logging.StreamHandler()]
    )
    
    try:
        # 1. åŠ è½½æ•°æ®
        sentiment_df = load_sentiment_data(args.sentiment_file)
        prices_df = load_price_data(args.prices_file)
        
        # 2. ç”Ÿæˆå› å­
        factors_df = generate_factors(sentiment_df)
        
        # 3. è®¡ç®—IC
        ic_df = calculate_ic(factors_df, prices_df)
        
        # 4. è¯„ä¼°å› å­
        eval_results = evaluate_factors(ic_df)
        
        # 5. ä¿å­˜ç»“æœ
        save_results(factors_df, ic_df, eval_results, 
                    args.factor_output, args.ic_output, args.eval_output)
        
        # 6. æ‰“å°æ‘˜è¦
        print_evaluation_summary(eval_results)
        
        print(f"\nâœ… å› å­ç”Ÿæˆå’Œè¯„ä¼°å®Œæˆ!")
        print(f"ğŸ“ å› å­æ•°æ®: {args.factor_output}")
        print(f"ğŸ“ ICæ•°æ®: {args.ic_output}")
        print(f"ğŸ“ è¯„ä¼°ç»“æœ: {args.eval_output}")
        
    except Exception as e:
        logging.error(f"å› å­ç”Ÿæˆå’Œè¯„ä¼°å¤±è´¥: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())

