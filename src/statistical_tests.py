#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
statistical_tests.py
---------------------------------
ICç»Ÿè®¡æ£€éªŒæ¨¡å— - ç”Ÿäº§çº§é‡åŒ–å› å­ç»Ÿè®¡æ£€éªŒ

åŠŸèƒ½åŒ…æ‹¬ï¼š
- ICæ—¶é—´åºåˆ—çš„t-statisticè®¡ç®—ï¼ˆNewey-Westè°ƒæ•´ï¼‰
- p-valueè®¡ç®—ï¼ˆå•å°¾/åŒå°¾æ£€éªŒï¼‰
- Information Ratio (IR) è®¡ç®—
- å¹´åŒ–IRå’Œç½®ä¿¡åŒºé—´
- è‡ªç›¸å…³è°ƒæ•´åçš„ç»Ÿè®¡æ£€éªŒ
- å¤šé‡æ¯”è¾ƒæ ¡æ­£ï¼ˆBonferroni, FDRï¼‰
- æ»šåŠ¨çª—å£ç»Ÿè®¡ç¨³å®šæ€§åˆ†æ

Author: Beta (NLP Sentiment Factor Refactor)
"""

import pandas as pd
import numpy as np
from scipy import stats
from typing import Dict, List, Tuple, Optional, Any
from dataclasses import dataclass
from pathlib import Path
import json
import logging


@dataclass
class ICStatisticalTest:
    """ICç»Ÿè®¡æ£€éªŒç»“æœæ•°æ®ç±»"""
    # åŸºæœ¬ç»Ÿè®¡é‡
    ic_mean: float
    ic_std: float
    ic_skewness: float
    ic_kurtosis: float
    n_observations: int
    
    # tç»Ÿè®¡é‡ï¼ˆæ ‡å‡†å’Œæ–°è°ƒæ•´ï¼‰
    t_stat_standard: float
    t_stat_newey_west: float
    
    # p-value
    p_value_one_tailed: float
    p_value_two_tailed: float
    p_value_newey_west: float
    
    # ä¿¡æ¯æ¯”ç‡
    ir_daily: float
    ir_annualized: float
    ir_confidence_interval_95: Tuple[float, float]
    
    # ç»Ÿè®¡æ˜¾è‘—æ€§åˆ¤æ–­
    is_significant_5pct: bool
    is_significant_1pct: bool
    is_significant_newey_west_5pct: bool
    
    # è‡ªç›¸å…³è°ƒæ•´
    autocorrelation_lag1: float
    effective_sample_size: float
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸æ ¼å¼"""
        return {
            'ic_mean': round(self.ic_mean, 6),
            'ic_std': round(self.ic_std, 6),
            'ic_skewness': round(self.ic_skewness, 4),
            'ic_kurtosis': round(self.ic_kurtosis, 4),
            'n_observations': self.n_observations,
            't_stat_standard': round(self.t_stat_standard, 4),
            't_stat_newey_west': round(self.t_stat_newey_west, 4),
            'p_value_one_tailed': round(self.p_value_one_tailed, 6),
            'p_value_two_tailed': round(self.p_value_two_tailed, 6),
            'p_value_newey_west': round(self.p_value_newey_west, 6),
            'ir_daily': round(self.ir_daily, 4),
            'ir_annualized': round(self.ir_annualized, 4),
            'ir_ci_95_lower': round(self.ir_confidence_interval_95[0], 4),
            'ir_ci_95_upper': round(self.ir_confidence_interval_95[1], 4),
            'is_significant_5pct': self.is_significant_5pct,
            'is_significant_1pct': self.is_significant_1pct,
            'is_significant_newey_west_5pct': self.is_significant_newey_west_5pct,
            'autocorrelation_lag1': round(self.autocorrelation_lag1, 4),
            'effective_sample_size': round(self.effective_sample_size, 2)
        }


def calculate_newey_west_tstat(ic_series: pd.Series, lags: int = 5) -> float:
    """
    è®¡ç®—Newey-Westè°ƒæ•´çš„tç»Ÿè®¡é‡
    
    Newey-Westè°ƒæ•´ç”¨äºå¤„ç†æ—¶é—´åºåˆ—ä¸­çš„å¼‚æ–¹å·®å’Œè‡ªç›¸å…³é—®é¢˜ï¼Œ
    æ˜¯é‡åŒ–é‡‘èä¸­ICæ£€éªŒçš„æ ‡å‡†åšæ³•ã€‚
    
    Args:
        ic_series: ICæ—¶é—´åºåˆ—
        lags: æ»åé˜¶æ•°ï¼Œé»˜è®¤5ï¼ˆçº¦ä¸€å‘¨äº¤æ˜“æ—¥ï¼‰
        
    Returns:
        Newey-Westè°ƒæ•´åçš„tç»Ÿè®¡é‡
    """
    if len(ic_series) < lags + 2:
        return np.nan
    
    ic_array = ic_series.dropna().values
    n = len(ic_array)
    ic_mean = np.mean(ic_array)
    
    # è®¡ç®—æ–¹å·®
    residuals = ic_array - ic_mean
    variance = np.sum(residuals ** 2) / n
    
    # Newey-Westè°ƒæ•´
    for lag in range(1, lags + 1):
        weight = 1 - lag / (lags + 1)
        autocov = np.sum(residuals[:-lag] * residuals[lag:]) / n
        variance += 2 * weight * autocov
    
    # ç¡®ä¿æ–¹å·®ä¸ºæ­£
    variance = max(variance, 1e-10)
    
    # è®¡ç®—æ ‡å‡†è¯¯
    se = np.sqrt(variance / n)
    
    # tç»Ÿè®¡é‡
    t_stat = ic_mean / se if se > 0 else 0
    
    return t_stat


def calculate_autocorrelation(ic_series: pd.Series, max_lags: int = 5) -> Dict[str, float]:
    """
    è®¡ç®—ICåºåˆ—çš„è‡ªç›¸å…³ç³»æ•°
    
    Args:
        ic_series: ICæ—¶é—´åºåˆ—
        max_lags: æœ€å¤§æ»åé˜¶æ•°
        
    Returns:
        åŒ…å«å„é˜¶è‡ªç›¸å…³ç³»æ•°çš„å­—å…¸
    """
    ic_clean = ic_series.dropna()
    n = len(ic_clean)
    
    if n < max_lags + 2:
        return {f'lag_{i}': 0.0 for i in range(1, max_lags + 1)}
    
    autocorr = {}
    for lag in range(1, max_lags + 1):
        if n > lag:
            corr = np.corrcoef(ic_clean[:-lag], ic_clean[lag:])[0, 1]
            autocorr[f'lag_{lag}'] = 0.0 if np.isnan(corr) else round(corr, 4)
        else:
            autocorr[f'lag_{lag}'] = 0.0
    
    return autocorr


def calculate_effective_sample_size(ic_series: pd.Series, max_lags: int = 5) -> float:
    """
    è®¡ç®—æœ‰æ•ˆæ ·æœ¬é‡ï¼ˆè€ƒè™‘è‡ªç›¸å…³ï¼‰
    
    å…¬å¼: n_eff = n / (1 + 2 * sum(autocorrelations))
    
    Args:
        ic_series: ICæ—¶é—´åºåˆ—
        max_lags: æœ€å¤§æ»åé˜¶æ•°
        
    Returns:
        æœ‰æ•ˆæ ·æœ¬é‡
    """
    n = len(ic_series.dropna())
    autocorr = calculate_autocorrelation(ic_series, max_lags)
    
    # è®¡ç®—è‡ªç›¸å…³å’Œ
    autocorr_sum = sum(max(0, v) for v in autocorr.values())  # åªè€ƒè™‘æ­£è‡ªç›¸å…³
    
    # æœ‰æ•ˆæ ·æœ¬é‡
    n_eff = n / (1 + 2 * autocorr_sum) if autocorr_sum >= 0 else n
    
    return max(n_eff, 10)  # è‡³å°‘10ä¸ªæ ·æœ¬


def calculate_information_ratio(
    ic_series: pd.Series, 
    annualization_factor: int = 252
) -> Tuple[float, float, Tuple[float, float]]:
    """
    è®¡ç®—Information Ratio (IR)
    
    IR = IC_mean / IC_std
    
    Args:
        ic_series: ICæ—¶é—´åºåˆ—
        annualization_factor: å¹´åŒ–å› å­ï¼ˆæ—¥åº¦æ•°æ®=252ï¼‰
        
    Returns:
        (æ—¥åº¦IR, å¹´åŒ–IR, 95%ç½®ä¿¡åŒºé—´)
    """
    ic_clean = ic_series.dropna()
    n = len(ic_clean)
    
    if n < 2:
        return 0.0, 0.0, (0.0, 0.0)
    
    ic_mean = ic_clean.mean()
    ic_std = ic_clean.std()
    
    # æ—¥åº¦IR
    ir_daily = ic_mean / ic_std if ic_std > 0 else 0.0
    
    # å¹´åŒ–IR
    ir_annual = ir_daily * np.sqrt(annualization_factor)
    
    # 95%ç½®ä¿¡åŒºé—´ï¼ˆåŸºäºæ ‡å‡†è¯¯ï¼‰
    se = ic_std / np.sqrt(n)
    ci_lower = (ic_mean - 1.96 * se) / ic_std if ic_std > 0 else 0.0
    ci_upper = (ic_mean + 1.96 * se) / ic_std if ic_std > 0 else 0.0
    
    return ir_daily, ir_annual, (round(ci_lower, 4), round(ci_upper, 4))


def perform_ic_statistical_test(
    ic_series: pd.Series,
    ic_type: str = "IC",
    newey_west_lags: int = 5
) -> ICStatisticalTest:
    """
    æ‰§è¡Œå®Œæ•´çš„ICç»Ÿè®¡æ£€éªŒ
    
    Args:
        ic_series: ICæ—¶é—´åºåˆ—ï¼ˆæ—¥åº¦ï¼‰
        ic_type: ICç±»å‹æ ‡è¯†ï¼ˆç”¨äºæ—¥å¿—ï¼‰
        newey_west_lags: Newey-Westæ»åé˜¶æ•°
        
    Returns:
        ICStatisticalTestå¯¹è±¡
    """
    ic_clean = ic_series.dropna()
    n = len(ic_clean)
    
    if n < 10:
        logging.warning(f"{ic_type}æ ·æœ¬é‡ä¸è¶³({n})ï¼Œç»Ÿè®¡æ£€éªŒå¯èƒ½ä¸å¯é ")
    
    # åŸºæœ¬ç»Ÿè®¡é‡
    ic_mean = ic_clean.mean()
    ic_std = ic_clean.std()
    ic_skewness = ic_clean.skew()
    ic_kurtosis = ic_clean.kurtosis()
    
    # æ ‡å‡†tç»Ÿè®¡é‡
    t_stat_standard = ic_mean / (ic_std / np.sqrt(n)) if ic_std > 0 else 0.0
    
    # Newey-Westè°ƒæ•´tç»Ÿè®¡é‡
    t_stat_newey_west = calculate_newey_west_tstat(ic_clean, newey_west_lags)
    
    # p-value
    p_value_two_tailed = 2 * (1 - stats.t.cdf(abs(t_stat_standard), n - 1))
    p_value_one_tailed = 1 - stats.t.cdf(abs(t_stat_standard), n - 1)
    p_value_nw = 2 * (1 - stats.t.cdf(abs(t_stat_newey_west), n - 1))
    
    # Information Ratio
    ir_daily, ir_annual, ir_ci = calculate_information_ratio(ic_clean)
    
    # è‡ªç›¸å…³
    autocorr = calculate_autocorrelation(ic_clean)
    autocorr_lag1 = autocorr.get('lag_1', 0.0)
    n_eff = calculate_effective_sample_size(ic_clean)
    
    # æ˜¾è‘—æ€§åˆ¤æ–­
    is_sig_5pct = p_value_two_tailed < 0.05
    is_sig_1pct = p_value_two_tailed < 0.01
    is_sig_nw_5pct = p_value_nw < 0.05
    
    return ICStatisticalTest(
        ic_mean=round(ic_mean, 6),
        ic_std=round(ic_std, 6),
        ic_skewness=round(ic_skewness, 4),
        ic_kurtosis=round(ic_kurtosis, 4),
        n_observations=n,
        t_stat_standard=round(t_stat_standard, 4),
        t_stat_newey_west=round(t_stat_newey_west, 4),
        p_value_one_tailed=round(p_value_one_tailed, 6),
        p_value_two_tailed=round(p_value_two_tailed, 6),
        p_value_newey_west=round(p_value_nw, 6),
        ir_daily=round(ir_daily, 4),
        ir_annualized=round(ir_annual, 4),
        ir_confidence_interval_95=ir_ci,
        is_significant_5pct=is_sig_5pct,
        is_significant_1pct=is_sig_1pct,
        is_significant_newey_west_5pct=is_sig_nw_5pct,
        autocorrelation_lag1=round(autocorr_lag1, 4),
        effective_sample_size=round(n_eff, 2)
    )


def perform_multiple_comparison_correction(
    p_values: List[float],
    method: str = "bonferroni",
    alpha: float = 0.05
) -> Dict[str, Any]:
    """
    å¤šé‡æ¯”è¾ƒæ ¡æ­£
    
    Args:
        p_values: på€¼åˆ—è¡¨
        method: æ ¡æ­£æ–¹æ³• ('bonferroni', 'fdr_bh')
        alpha: æ˜¾è‘—æ€§æ°´å¹³
        
    Returns:
        æ ¡æ­£ç»“æœå­—å…¸
    """
    n = len(p_values)
    
    if method == "bonferroni":
        # Bonferroniæ ¡æ­£
        corrected_pvalues = [min(p * n, 1.0) for p in p_values]
        significant = [p < alpha for p in corrected_pvalues]
        
        return {
            'method': 'Bonferroni',
            'original_pvalues': p_values,
            'corrected_pvalues': corrected_pvalues,
            'significant': significant,
            'n_tests': n,
            'alpha': alpha
        }
    
    elif method == "fdr_bh":
        # Benjamini-Hochberg FDRæ ¡æ­£
        sorted_indices = np.argsort(p_values)
        sorted_pvalues = np.array(p_values)[sorted_indices]
        
        corrected = np.zeros(n)
        for i, p in enumerate(sorted_pvalues):
            corrected[sorted_indices[i]] = min(p * n / (i + 1), 1.0)
        
        significant = [p < alpha for p in corrected]
        
        return {
            'method': 'Benjamini-Hochberg FDR',
            'original_pvalues': p_values,
            'corrected_pvalues': corrected.tolist(),
            'significant': significant,
            'n_tests': n,
            'alpha': alpha
        }
    
    else:
        raise ValueError(f"æœªçŸ¥çš„æ ¡æ­£æ–¹æ³•: {method}")


def rolling_ic_stability_analysis(
    ic_series: pd.Series,
    window: int = 63,  # çº¦3ä¸ªæœˆ
    step: int = 21     # çº¦1ä¸ªæœˆ
) -> pd.DataFrame:
    """
    æ»šåŠ¨çª—å£ICç¨³å®šæ€§åˆ†æ
    
    Args:
        ic_series: ICæ—¶é—´åºåˆ—
        window: æ»šåŠ¨çª—å£å¤§å°
        step: æ»šåŠ¨æ­¥é•¿
        
    Returns:
        æ»šåŠ¨ç»Ÿè®¡ç»“æœDataFrame
    """
    ic_clean = ic_series.dropna().reset_index(drop=True)
    results = []
    
    for start in range(0, len(ic_clean) - window + 1, step):
        end = start + window
        window_ic = ic_clean.iloc[start:end]
        
        if len(window_ic) < window * 0.8:  # è¦æ±‚è‡³å°‘80%æ•°æ®
            continue
        
        ic_mean = window_ic.mean()
        ic_std = window_ic.std()
        ir = ic_mean / ic_std if ic_std > 0 else 0
        
        # ç®€å•tç»Ÿè®¡é‡
        t_stat = ic_mean / (ic_std / np.sqrt(len(window_ic))) if ic_std > 0 else 0
        
        results.append({
            'window_start': start,
            'window_end': end,
            'ic_mean': round(ic_mean, 4),
            'ic_std': round(ic_std, 4),
            'ir': round(ir, 4),
            't_stat': round(t_stat, 4),
            'n_obs': len(window_ic)
        })
    
    return pd.DataFrame(results)


def generate_ic_statistical_report(
    ic_df: pd.DataFrame,
    output_path: str = "reports/ic_statistical_report.json"
) -> Dict[str, Any]:
    """
    ç”ŸæˆICç»Ÿè®¡æ£€éªŒå®Œæ•´æŠ¥å‘Š
    
    Args:
        ic_df: åŒ…å«ICå’ŒRankICçš„DataFrame
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        
    Returns:
        å®Œæ•´æŠ¥å‘Šå­—å…¸
    """
    report = {
        'report_type': 'IC Statistical Test Report',
        'generated_at': pd.Timestamp.now().isoformat(),
        'methodology': {
            't_statistic': 'Standard t-test with Newey-West adjustment',
            'newey_west_lags': 5,
            'ir_annualization': 252,
            'confidence_level': 0.95
        }
    }
    
    # ICç»Ÿè®¡æ£€éªŒ
    if 'IC' in ic_df.columns:
        ic_test = perform_ic_statistical_test(ic_df['IC'], ic_type="IC")
        report['ic_test'] = ic_test.to_dict()
    
    # Rank-ICç»Ÿè®¡æ£€éªŒ
    if 'RankIC' in ic_df.columns:
        rank_ic_test = perform_ic_statistical_test(ic_df['RankIC'], ic_type="Rank-IC")
        report['rank_ic_test'] = rank_ic_test.to_dict()
    
    # æ»šåŠ¨ç¨³å®šæ€§åˆ†æ
    if 'IC' in ic_df.columns:
        rolling_analysis = rolling_ic_stability_analysis(ic_df['IC'])
        report['rolling_stability'] = {
            'window_size': 63,
            'step_size': 21,
            'n_windows': len(rolling_analysis),
            'ic_mean_std': round(rolling_analysis['ic_mean'].std(), 4) if len(rolling_analysis) > 0 else 0,
            'windows': rolling_analysis.to_dict('records')
        }
    
    # ä¿å­˜æŠ¥å‘Š
    output_path = Path(output_path)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(report, f, ensure_ascii=False, indent=2)
    
    logging.info(f"ICç»Ÿè®¡æ£€éªŒæŠ¥å‘Šå·²ä¿å­˜: {output_path}")
    
    return report


def print_ic_test_summary(test_result: ICStatisticalTest, ic_type: str = "IC") -> None:
    """
    æ‰“å°ICæ£€éªŒç»“æœæ‘˜è¦
    
    Args:
        test_result: ICStatisticalTestå¯¹è±¡
        ic_type: ICç±»å‹åç§°
    """
    print(f"\n{'='*60}")
    print(f"ğŸ“Š {ic_type} ç»Ÿè®¡æ£€éªŒç»“æœ")
    print(f"{'='*60}")
    
    print(f"\nåŸºæœ¬ç»Ÿè®¡é‡:")
    print(f"  â€¢ æ ·æœ¬é‡: {test_result.n_observations}")
    print(f"  â€¢ ICå‡å€¼: {test_result.ic_mean:.6f}")
    print(f"  â€¢ ICæ ‡å‡†å·®: {test_result.ic_std:.6f}")
    print(f"  â€¢ ååº¦: {test_result.ic_skewness:.4f}")
    print(f"  â€¢ å³°åº¦: {test_result.ic_kurtosis:.4f}")
    
    print(f"\ntç»Ÿè®¡é‡:")
    print(f"  â€¢ æ ‡å‡†tç»Ÿè®¡é‡: {test_result.t_stat_standard:.4f}")
    print(f"  â€¢ Newey-Westè°ƒæ•´t: {test_result.t_stat_newey_west:.4f}")
    
    print(f"\np-value:")
    print(f"  â€¢ åŒå°¾p-value: {test_result.p_value_two_tailed:.6f}")
    print(f"  â€¢ å•å°¾p-value: {test_result.p_value_one_tailed:.6f}")
    print(f"  â€¢ Newey-West p-value: {test_result.p_value_newey_west:.6f}")
    
    print(f"\nInformation Ratio:")
    print(f"  â€¢ æ—¥åº¦IR: {test_result.ir_daily:.4f}")
    print(f"  â€¢ å¹´åŒ–IR: {test_result.ir_annualized:.4f}")
    print(f"  â€¢ IR 95% CI: [{test_result.ir_confidence_interval_95[0]:.4f}, {test_result.ir_confidence_interval_95[1]:.4f}]")
    
    print(f"\næ˜¾è‘—æ€§åˆ¤æ–­:")
    sig_5 = "âœ… æ˜¾è‘—" if test_result.is_significant_5pct else "âŒ ä¸æ˜¾è‘—"
    sig_1 = "âœ… æ˜¾è‘—" if test_result.is_significant_1pct else "âŒ ä¸æ˜¾è‘—"
    sig_nw = "âœ… æ˜¾è‘—" if test_result.is_significant_newey_west_5pct else "âŒ ä¸æ˜¾è‘—"
    print(f"  â€¢ 5%æ˜¾è‘—æ€§æ°´å¹³: {sig_5}")
    print(f"  â€¢ 1%æ˜¾è‘—æ€§æ°´å¹³: {sig_1}")
    print(f"  â€¢ Newey-West 5%: {sig_nw}")
    
    print(f"\nè‡ªç›¸å…³åˆ†æ:")
    print(f"  â€¢ ä¸€é˜¶è‡ªç›¸å…³: {test_result.autocorrelation_lag1:.4f}")
    print(f"  â€¢ æœ‰æ•ˆæ ·æœ¬é‡: {test_result.effective_sample_size:.1f}")
    
    print(f"{'='*60}")


if __name__ == "__main__":
    # ç¤ºä¾‹ç”¨æ³•
    import argparse
    
    parser = argparse.ArgumentParser(description="ICç»Ÿè®¡æ£€éªŒ")
    parser.add_argument("--ic_file", default="data/processed/ic_results.csv", help="ICæ•°æ®æ–‡ä»¶")
    parser.add_argument("--output", default="reports/ic_statistical_report.json", help="è¾“å‡ºæŠ¥å‘Šè·¯å¾„")
    
    args = parser.parse_args()
    
    logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')
    
    if Path(args.ic_file).exists():
        ic_df = pd.read_csv(args.ic_file)
        report = generate_ic_statistical_report(ic_df, args.output)
        
        # æ‰“å°æ‘˜è¦
        if 'ic_test' in report:
            test = ICStatisticalTest(**report['ic_test'])
            print_ic_test_summary(test, "IC")
        
        if 'rank_ic_test' in report:
            test = ICStatisticalTest(**report['rank_ic_test'])
            print_ic_test_summary(test, "Rank-IC")
    else:
        print(f"âŒ ICæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {args.ic_file}")
